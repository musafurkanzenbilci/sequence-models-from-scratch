{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f9136d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext import datasets\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07036fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1949-01'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv\"\n",
    "data = pd.read_csv(url)\n",
    "passengers = data.Passengers.values.astype(np.float32)\n",
    "data.Month[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdcb2866",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AirlineDataset(Dataset):\n",
    "    def __init__(self, transform=None):\n",
    "        super().__init__()\n",
    "        URL = \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv\"\n",
    "        self.data = pd.read_csv(URL)\n",
    "        self.passengers = self.data.Passengers\n",
    "        self.transform = transform\n",
    "\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        month, passenger = self.data.Month[index], self.data.Passengers[index]\n",
    "        return month, passenger\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "818d546d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = AirlineDataset()\n",
    "loader = DataLoader(dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c833ebbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DinoNameDataset(Dataset):\n",
    "    def __init__(self, transform=None, sos_key='<SOS>', eos_key='<EOS>', pad_key='<PAD>'):\n",
    "        super().__init__()\n",
    "        self.transform = transform\n",
    "        # file_path = \"/Users/musazenbilci/Desktop/mosesopposite/DeepLearningAI-RNN/W1A2/dinos.txt\"\n",
    "        file_path = \"/Users/musazenbilci/Desktop/mosesopposite/andrej/makemore/tr_names.txt\"\n",
    "        with open(file_path, 'r') as file:\n",
    "            self.data = file.readlines()\n",
    "        self.max_len = len(max(self.data, key=len))\n",
    "        self.sos_key = sos_key\n",
    "        self.eos_key = eos_key\n",
    "        self.pad_key = pad_key\n",
    "        self.alphabet = [self.sos_key] + list(set(''.join(self.data).lower())) + [self.eos_key, self.pad_key] \n",
    "        self.i2l = {idx: letter for idx, letter in enumerate(self.alphabet) }\n",
    "        self.l2i = {letter: torch.tensor(idx) for idx, letter in enumerate(self.alphabet) }\n",
    "        self.VOCAB_SIZE = len(self.l2i)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data = self.tokenize(self.data[index].lower()) # if self.transform  else self.data[index]\n",
    "        return data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def tokenize(self, x):\n",
    "        return torch.tensor([self.l2i[self.sos_key]] + [self.l2i[c.lower()] if c!='\\n' else self.l2i[self.eos_key] for c in list(x)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c9ea6515",
   "metadata": {},
   "outputs": [],
   "source": [
    "ddataset = DinoNameDataset()\n",
    "alphabet = ddataset.alphabet\n",
    "i2l = ddataset.i2l\n",
    "l2i = ddataset.l2i\n",
    "VOCAB_SIZE = ddataset.VOCAB_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b3824e68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'iÌ‡' in ddataset.alphabet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "94aaf438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alphabet = ['<SOS>'] + ddataset.alphabet + ['<EOS>', '<PAD>'] \n",
    "# i2l = {idx: letter for idx, letter in enumerate(alphabet) }\n",
    "# l2i = {letter: torch.tensor(idx) for idx, letter in enumerate(alphabet) }\n",
    "# VOCAB_SIZE = len(l2i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6ac04117",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_collate(batch):\n",
    "    sequences = batch[:]\n",
    "    padded_sequences = pad_sequence(sequences, batch_first=True, padding_value=l2i['<PAD>'])\n",
    "    return padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "90abeae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, val_data, test_data = random_split(ddataset, [0.8, 0.1, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3db4f01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dloader = DataLoader(train_data, batch_size=4, shuffle=True, collate_fn=pad_collate)\n",
    "val_loader = DataLoader(val_data, batch_size=4, shuffle=False, collate_fn=pad_collate)\n",
    "test_loader = DataLoader(test_data, batch_size=4, shuffle=False, collate_fn=pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4d065f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize = lambda a: torch.tensor([l2i['<SOS>']] + [l2i[c.lower()] if c!='\\n' else l2i['<EOS>'] for c in list(a)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0fa4bd9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 14])\n"
     ]
    }
   ],
   "source": [
    "len(dloader)\n",
    "for word in dloader:\n",
    "    print(word.shape)\n",
    "#     # print(word)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20467910",
   "metadata": {},
   "source": [
    "<img src=\"../images/rnn_step_forward_figure2_v3a.png\" style=\"width:700px;height:300px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "426948be",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNNCell(nn.Module):\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(vocab_size, vocab_size, bias=False) # Waa\n",
    "        self.linear2 = nn.Linear(vocab_size, vocab_size, bias=True) # Wax + ba\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "        self.final = nn.Linear(vocab_size, vocab_size, bias=True) # Wya + by\n",
    "\n",
    "    def forward(self, x, previous_a): # also called hidden state\n",
    "        aa = self.linear1(previous_a)\n",
    "        ax = self.linear2(x)\n",
    "        x = torch.add(aa, ax)\n",
    "        a = self.tanh(x)\n",
    "        x = self.final(a)\n",
    "        return x, a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "48be7979",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell = RNNCell(VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a444824",
   "metadata": {},
   "source": [
    "<img src=\"/Users/musazenbilci/Desktop/mosesopposite/DeepLearningAI-RNN/W1A1/images/RNN.png\" style=\"width:500;height:300px;\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "6cceb3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_one_hot = lambda x: torch.nn.functional.one_hot(x, VOCAB_SIZE).to(torch.float32)\n",
    "make_zero_hot = lambda : torch.zeros(VOCAB_SIZE).to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "6b9115a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH_LOSS 20.82814035192132\n",
      "EPOCH_LOSS 16.60375009709969\n",
      "EPOCH_LOSS 15.394904699642211\n",
      "EPOCH_LOSS 14.71077059286957\n",
      "EPOCH_LOSS 14.165701747406274\n",
      "EPOCH_LOSS 13.823744678637013\n",
      "EPOCH_LOSS 13.589067362093678\n",
      "EPOCH_LOSS 13.385934456018731\n",
      "EPOCH_LOSS 13.172507057975357\n",
      "EPOCH_LOSS 13.112891293053204\n",
      "EPOCH_LOSS 13.012882166852554\n",
      "EPOCH_LOSS 13.000476781278849\n",
      "EPOCH_LOSS 12.83463465794921\n",
      "EPOCH_LOSS 12.730492672494924\n",
      "EPOCH_LOSS 12.686102047174549\n",
      "EPOCH_LOSS 12.543046530957023\n",
      "EPOCH_LOSS 12.524487066470707\n",
      "EPOCH_LOSS 12.681524048559368\n",
      "EPOCH_LOSS 12.471853277646005\n",
      "EPOCH_LOSS 12.392977533396333\n",
      "EPOCH_LOSS 12.39987679120774\n",
      "EPOCH_LOSS 12.896046592155471\n",
      "EPOCH_LOSS 12.794668367520595\n",
      "EPOCH_LOSS 12.614421548089013\n",
      "LR Changed 0.001\n",
      "EPOCH_LOSS 11.416940778804323\n",
      "EPOCH_LOSS 10.976396360434592\n",
      "EPOCH_LOSS 10.818512260603407\n",
      "EPOCH_LOSS 10.714353054917106\n",
      "EPOCH_LOSS 10.614205507561564\n",
      "EPOCH_LOSS 10.543386969560137\n",
      "EPOCH_LOSS 10.481041078145305\n",
      "EPOCH_LOSS 10.454274164667973\n",
      "EPOCH_LOSS 10.389782273521027\n",
      "EPOCH_LOSS 10.369979108994206\n",
      "EPOCH_LOSS 10.318428427601853\n",
      "EPOCH_LOSS 10.299711104948074\n",
      "LR Changed 0.0001\n",
      "EPOCH_LOSS 10.128887853895625\n",
      "EPOCH_LOSS 10.110711254334698\n",
      "EPOCH_LOSS 10.127672490508607\n",
      "EPOCH_LOSS 10.114988325706994\n",
      "EPOCH_LOSS 10.090464550613737\n",
      "EPOCH_LOSS 10.105452115802715\n",
      "EPOCH_LOSS 10.081900873221457\n",
      "EPOCH_LOSS 10.078190369997174\n",
      "EPOCH_LOSS 10.104687059763819\n",
      "EPOCH_LOSS 10.07113400932091\n",
      "LR Changed 1e-05\n",
      "EPOCH_LOSS 10.072440483219301\n",
      "EPOCH_LOSS 10.05091708471688\n",
      "EPOCH_LOSS 10.066725282619396\n",
      "EPOCH_LOSS 10.061800891455883\n",
      "EPOCH_LOSS 10.068915228980282\n",
      "EPOCH_LOSS 10.049343527449915\n",
      "EPOCH_LOSS 10.04876075203841\n",
      "EPOCH_LOSS 10.069364114043614\n",
      "EPOCH_LOSS 10.064124868328994\n",
      "LR Changed 1.0000000000000002e-06\n",
      "EPOCH_LOSS 10.065078548233336\n",
      "EPOCH_LOSS 10.045868844337141\n",
      "EPOCH_LOSS 10.057674765897294\n",
      "EPOCH_LOSS 10.066733974187324\n",
      "EPOCH_LOSS 10.045797961764038\n",
      "EPOCH_LOSS 10.061851922189817\n",
      "EPOCH_LOSS 10.045685829905173\n",
      "EPOCH_LOSS 10.055203390850997\n",
      "EPOCH_LOSS 10.064961082612475\n",
      "LR Changed 1.0000000000000002e-07\n",
      "EPOCH_LOSS 10.045708915451542\n",
      "EPOCH_LOSS 10.045523059554398\n",
      "EPOCH_LOSS 10.045654064354798\n",
      "EPOCH_LOSS 10.045616422003755\n",
      "EPOCH_LOSS 10.045296387126049\n",
      "EPOCH_LOSS 10.04551388672553\n",
      "EPOCH_LOSS 10.069736417538175\n",
      "EPOCH_LOSS 10.061690089680875\n",
      "EPOCH_LOSS 10.061453113642832\n",
      "LR Changed 1.0000000000000004e-08\n",
      "EPOCH_LOSS 10.06160825265882\n",
      "EPOCH_LOSS 10.045162628870457\n",
      "EPOCH_LOSS 10.04543677251786\n",
      "EPOCH_LOSS 10.04552450690729\n",
      "EPOCH_LOSS 10.045355534724271\n",
      "EPOCH_LOSS 10.045524775283411\n",
      "EPOCH_LOSS 10.045442217340073\n",
      "EPOCH_LOSS 10.045297335678091\n",
      "EPOCH_LOSS 10.045435584460696\n",
      "EPOCH_LOSS 10.045258950209245\n",
      "EPOCH_LOSS 10.045190832034374\n",
      "EPOCH_LOSS 10.05714452957424\n",
      "EPOCH_LOSS 10.056995902365694\n",
      "EPOCH_LOSS 10.045314380743852\n",
      "EPOCH_LOSS 10.057251103688031\n",
      "EPOCH_LOSS 10.045450295244033\n",
      "EPOCH_LOSS 10.0643938734817\n",
      "EPOCH_LOSS 10.045611894999942\n",
      "EPOCH_LOSS 10.057156502269208\n",
      "EPOCH_LOSS 10.045426536041\n",
      "EPOCH_LOSS 10.064818835041175\n",
      "EPOCH_LOSS 10.045330625105029\n",
      "EPOCH_LOSS 10.045166940893978\n",
      "EPOCH_LOSS 10.04561348631978\n",
      "EPOCH_LOSS 10.045340436588353\n",
      "EPOCH_LOSS 10.061534613370895\n",
      "EPOCH_LOSS 10.045255876146257\n"
     ]
    }
   ],
   "source": [
    "from torch import float32\n",
    "\n",
    "initial_lr = 1e-2\n",
    "cell = RNNCell(VOCAB_SIZE)\n",
    "optimizer = optim.SGD(cell.parameters(), lr=initial_lr)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=8, threshold=5e-2)\n",
    "a0 = make_zero_hot()\n",
    "\n",
    "EPOCH=100\n",
    "\n",
    "for ep in range(EPOCH):\n",
    "    epoch_loss = 0\n",
    "    for batch in dloader:\n",
    "        batch_loss = 0\n",
    "        for word in batch:\n",
    "            a_prev = a0\n",
    "            loss = 0\n",
    "            optimizer.zero_grad()\n",
    "            for ci in range(len(word)-1):\n",
    "                if word[ci] == l2i[ddataset.sos_key]:\n",
    "                    continue\n",
    "                \n",
    "                onehot = make_one_hot(word[ci])\n",
    "                logits, act = cell(onehot, a_prev)\n",
    "                loss += criterion(logits, word[ci+1])\n",
    "                a_prev = act\n",
    "\n",
    "                if word[ci] == l2i[ddataset.eos_key]: # skip paddings\n",
    "                    break\n",
    "            # print(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            batch_loss += loss.item()\n",
    "            # break\n",
    "        # print(\"BATCH_LOSS\", batch_loss / 4)\n",
    "        epoch_loss += batch_loss / 4\n",
    "        # break\n",
    "    print(\"EPOCH_LOSS\", epoch_loss / 384)\n",
    "    scheduler.step(epoch_loss / 384, ep)\n",
    "    if initial_lr != optimizer.param_groups[0]['lr']:\n",
    "        print(f\"LR Changed {optimizer.param_groups[0]['lr']}\")\n",
    "        initial_lr = optimizer.param_groups[0]['lr']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "67db0d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(cell.state_dict, './turkish_rnn_cell_loss9.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1db6929",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(cell.state_dict, './rnn_cell_loss16.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ffd0851f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "a00 = a0\n",
    "a00[0] = 0\n",
    "a00 = a00.to(float32)\n",
    "print(a0.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "772413f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/f9/kqml6rjn5g5688g1y7fn01ch0000gn/T/ipykernel_21005/894917494.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input, a_prev = make_one_hot(torch.tensor(test_ind)), make_zero_hot() # make_one_hot(torch.tensor(test_ind2))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'zahan'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = ''\n",
    "# input, a_prev = a0.to(float32), a00.to(float32)\n",
    "test_ind = l2i['z']\n",
    "test_ind2 = l2i['b']\n",
    "input, a_prev = make_one_hot(torch.tensor(test_ind)), make_zero_hot() # make_one_hot(torch.tensor(test_ind2))\n",
    "# output += i2l[test_ind2.item()]\n",
    "output += i2l[test_ind.item()]\n",
    "while True:\n",
    "    logits, act = cell(input, a_prev)\n",
    "    probs = torch.softmax(logits, 0)\n",
    "    chosen = torch.argmax(probs)\n",
    "    if chosen == l2i['<EOS>']:\n",
    "        break\n",
    "    output += i2l[chosen.item()]\n",
    "    input = torch.nn.functional.one_hot(chosen, VOCAB_SIZE).to(float32)\n",
    "    a_prev = act\n",
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
